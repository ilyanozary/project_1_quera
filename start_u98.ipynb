{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath ='U98.xlsx'\n",
    "data98 = pd.read_excel(filepath, sheet_name= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3_sheets = {\n",
    "    'U98P3S01': 'Food',\n",
    "    'U98P3S02': 'Tobacco',\n",
    "    'U98P3S03': 'Clothing',\n",
    "    'U98P3S04': 'Horsing',\n",
    "    'U98P3S05': 'FrrniTrue',\n",
    "    'U98P3S06': 'Health',\n",
    "    'U98P3S07': 'Transport',\n",
    "    'U98P3S08': 'Commrnication',\n",
    "    'U98P3S09': 'recreation',\n",
    "    'U98P3S11': 'Edrcation',\n",
    "    'U98P3S12': 'Hotel',\n",
    "    'U98P3S13': 'Miscellaneors',\n",
    "    'U98P3S14': 'Investment'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet_name, expense_type in p3_sheets.items():\n",
    "    if sheet_name in data98:\n",
    "        columns_to_rename = {}\n",
    "\n",
    "\n",
    "        if 'code' in data98[sheet_name].columns:\n",
    "            columns_to_rename['code'] = f'{expense_type}_Code'\n",
    "\n",
    "        if 'prrchased' in data98[sheet_name].columns:\n",
    "            columns_to_rename['prrchased'] = f'{expense_type}_Prrchased'\n",
    "\n",
    "        if 'gram' in data98[sheet_name].columns:\n",
    "            columns_to_rename['gram'] = f'{expense_type}_Gram'\n",
    "\n",
    "        if 'kilogram' in data98[sheet_name].columns:\n",
    "            columns_to_rename['kilogram'] = f'{expense_type}_Kilogram'\n",
    "\n",
    "        if 'price' in data98[sheet_name].columns:\n",
    "            columns_to_rename['price'] = f'{expense_type}_Price'\n",
    "\n",
    "        if 'valre' in data98[sheet_name].columns:\n",
    "            columns_to_rename['valre'] = f'{expense_type}_Valre'\n",
    "\n",
    "        if 'mortgage' in data98[sheet_name].columns:\n",
    "            columns_to_rename['mortgage'] = f'{expense_type}_Mortgage'\n",
    "\n",
    "\n",
    "        data98[sheet_name] = data98[sheet_name].rename(columns=columns_to_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98Data=pd.read_excel(filepath, sheet_name='U98Data')\n",
    "U98P1=pd.read_excel(filepath, sheet_name='U98P1')\n",
    "U98P2=pd.read_excel(filepath, sheet_name='U98P2')\n",
    "U98P3S01=pd.read_excel(filepath, sheet_name='U98P3S01')\n",
    "U98P3S02=pd.read_excel(filepath, sheet_name='U98P3S02')\n",
    "U98P3S03=pd.read_excel(filepath, sheet_name='U98P3S03')\n",
    "U98P3S04=pd.read_excel(filepath, sheet_name='U98P3S04')\n",
    "U98P3S05=pd.read_excel(filepath, sheet_name='U98P3S05')\n",
    "U98P3S06=pd.read_excel(filepath, sheet_name='U98P3S06')\n",
    "U98P3S07=pd.read_excel(filepath, sheet_name='U98P3S07')\n",
    "U98P3S08=pd.read_excel(filepath, sheet_name='U98P3S08')\n",
    "U98P3S09=pd.read_excel(filepath, sheet_name='U98P3S09')\n",
    "U98P3S11=pd.read_excel(filepath, sheet_name='U98P3S11')\n",
    "U98P3S12=pd.read_excel(filepath, sheet_name='U98P3S12')\n",
    "U98P3S13=pd.read_excel(filepath, sheet_name='U98P3S13')\n",
    "U98P3S14=pd.read_excel(filepath, sheet_name='U98P3S14')\n",
    "U98P4S01=pd.read_excel(filepath, sheet_name='U98P4S01')\n",
    "U98P4S02=pd.read_excel(filepath, sheet_name='U98P4S02')\n",
    "U98P4S03=pd.read_excel(filepath, sheet_name='U98P4S03')\n",
    "U98P4S04=pd.read_excel(filepath, sheet_name='U98P4S04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet_name, df in data98.items():\n",
    "    if 'Valre' in df.columns:\n",
    "        df['Valre'] = pd.to_nrmeric(df['Valre'], errors='coerce')\n",
    "\n",
    "    data98[sheet_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98Data = pd.read_excel(filepath, sheet_name='U98Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>MahMorajeh</th>\n",
       "      <th>Fasl</th>\n",
       "      <th>weight</th>\n",
       "      <th>khanevartype</th>\n",
       "      <th>Takmil</th>\n",
       "      <th>TakmilDescA</th>\n",
       "      <th>TakmilDescB</th>\n",
       "      <th>TakmilDescC</th>\n",
       "      <th>Jaygozin</th>\n",
       "      <th>JaygozinDescA</th>\n",
       "      <th>JaygozinDescB</th>\n",
       "      <th>JaygozinDescC</th>\n",
       "      <th>BlkAbdJaygozin</th>\n",
       "      <th>RadifJaygozin</th>\n",
       "      <th>province</th>\n",
       "      <th>town</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001000108</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1199.12892</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Markazi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001000111</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1199.12892</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Markazi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001000114</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1199.12892</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Markazi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001000117</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1199.12892</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Markazi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001000120</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1199.12892</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Markazi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Address  MahMorajeh  Fasl      weight  khanevartype  Takmil  \\\n",
       "0  10001000108          11     4  1199.12892             1       1   \n",
       "1  10001000111          11     4  1199.12892             1       2   \n",
       "2  10001000114          11     4  1199.12892             1       2   \n",
       "3  10001000117          11     4  1199.12892             1       2   \n",
       "4  10001000120          11     4  1199.12892             1       1   \n",
       "\n",
       "   TakmilDescA  TakmilDescB TakmilDescC  Jaygozin  JaygozinDescA  \\\n",
       "0          NaN          NaN         NaN       NaN            NaN   \n",
       "1          NaN          1.0         NaN       1.0            NaN   \n",
       "2          NaN          1.0         NaN       1.0            NaN   \n",
       "3          NaN          1.0         NaN       1.0            NaN   \n",
       "4          NaN          NaN         NaN       NaN            NaN   \n",
       "\n",
       "   JaygozinDescB  JaygozinDescC  BlkAbdJaygozin  RadifJaygozin province  town  \n",
       "0            NaN            NaN             NaN            NaN  Markazi     1  \n",
       "1            NaN            NaN             1.0            7.0  Markazi     1  \n",
       "2            NaN            NaN             1.0           13.0  Markazi     1  \n",
       "3            NaN            NaN             2.0           16.0  Markazi     1  \n",
       "4            NaN            NaN             NaN            NaN  Markazi     1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U98Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address             0.000000\n",
       "MahMorajeh          0.000000\n",
       "Fasl                0.000000\n",
       "weight              0.000000\n",
       "khanevartype        0.000000\n",
       "Takmil              0.000000\n",
       "TakmilDescA       100.000000\n",
       "TakmilDescB        76.258920\n",
       "TakmilDescC        99.829129\n",
       "Jaygozin           76.258920\n",
       "JaygozinDescA     100.000000\n",
       "JaygozinDescB     100.000000\n",
       "JaygozinDescC     100.000000\n",
       "BlkAbdJaygozin     76.258920\n",
       "RadifJaygozin      76.258920\n",
       "province            0.000000\n",
       "town                0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98Data.isnull().sum() / len(U98Data) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98Data_cleaned = U98Data.dropna(axis=1, thresh=int((1-threshold/100)*len(U98Data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address         0.0\n",
       "MahMorajeh      0.0\n",
       "Fasl            0.0\n",
       "weight          0.0\n",
       "khanevartype    0.0\n",
       "Takmil          0.0\n",
       "province        0.0\n",
       "town            0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98Data_cleaned.isnull().sum() / len(U98Data_cleaned) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address         0.0\n",
       "MahMorajeh      0.0\n",
       "Fasl            0.0\n",
       "weight          0.0\n",
       "khanevartype    0.0\n",
       "Takmil          0.0\n",
       "province        0.0\n",
       "town            0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98Data_cleaned.isnull().sum() / len(U98Data_cleaned) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates = U98Data_cleaned.duplicated().sum()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های دسته‌بندی‌شده:\n",
      "Index(['province'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = U98Data_cleaned.select_dtypes(include=['object']).columns\n",
    "print(\"ستون‌های دسته‌بندی‌شده:\")\n",
    "print(categorical_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های عددی:\n",
      "Index(['Address', 'MahMorajeh', 'Fasl', 'weight', 'khanevartype', 'Takmil',\n",
      "       'town'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nrmerical_columns = U98Data_cleaned.select_dtypes(include=['number']).columns\n",
    "print(\"ستون‌های عددی:\")\n",
    "print(nrmerical_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مقادیر منحصر به فرد در ستون province:\n",
      "['Markazi' 'Gilan' 'Mazandaran' 'AzarbaijanSharghi' 'AzarbaijanGharbi'\n",
      " 'Kermanshah' 'Kouzestan' 'Fars' 'Kerman' 'KhorasanRazavi' 'Esfahan'\n",
      " 'SistanBalouchestan' 'Kordestan' 'Hamedan' 'CharmahalBakhtiari'\n",
      " 'Lorestan' 'Ilam' 'KohkilouyeBoyerahamad' 'Boushehr' 'Zanjan' 'Semnan'\n",
      " 'Yazd' 'Hormozgan' 'Tehran' 'Ardebil' 'Qom' 'Qazvin' 'Golestan'\n",
      " 'KhorasanShomali' 'KhorasanJonoubi' 'Alborz']\n"
     ]
    }
   ],
   "source": [
    "unique_provinces = U98Data_cleaned['province'].unique()\n",
    "print(\"مقادیر منحصر به فرد در ستون province:\")\n",
    "print(unique_provinces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تعداد هر دسته در ستون province:\n",
      "province\n",
      "Tehran                   1463\n",
      "Golestan                 1041\n",
      "Hormozgan                 857\n",
      "Gilan                     857\n",
      "Hamedan                   788\n",
      "SistanBalouchestan        765\n",
      "KhorasanRazavi            745\n",
      "KhorasanShomali           694\n",
      "Esfahan                   686\n",
      "Fars                      672\n",
      "Kouzestan                 659\n",
      "KhorasanJonoubi           648\n",
      "CharmahalBakhtiari        648\n",
      "Kermanshah                632\n",
      "Zanjan                    614\n",
      "Yazd                      604\n",
      "AzarbaijanSharghi         594\n",
      "Markazi                   589\n",
      "Boushehr                  566\n",
      "AzarbaijanGharbi          554\n",
      "Kerman                    549\n",
      "KohkilouyeBoyerahamad     540\n",
      "Qom                       528\n",
      "Kordestan                 480\n",
      "Ardebil                   476\n",
      "Ilam                      474\n",
      "Semnan                    470\n",
      "Lorestan                  463\n",
      "Qazvin                    420\n",
      "Alborz                    413\n",
      "Mazandaran                409\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# مشاهده تعداد هر دسته‌بندی در ستون province\n",
    "province_cornts = U98Data_cleaned['province'].value_counts()\n",
    "print(\"تعداد هر دسته در ستون province:\")\n",
    "print(province_cornts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# دیکشنری برای انکود کردن مقادیر province\n",
    "province_encoding = {\n",
    "    'Markazi': '00', 'Gilan': '01', 'Mazandaran': '02', 'AzarbaijanSharghi': '03', \n",
    "    'AzarbaijanGharbi': '04', 'Kermanshah': '05', 'Korzestan': '06', 'Fars': '07', \n",
    "    'Kerman': '08', 'Khorasanrazavi': '09', 'Esfahan': '10', 'SistanBalorchestan': '11', \n",
    "    'Kordestan': '12', 'Hamedan': '13', 'CharmahalBakhtiari': '14', 'Lorestan': '15', \n",
    "    'Ilam': '16', 'KohkiloryeBoyerahamad': '17', 'Borshehr': '18', 'Zanjan': '19', \n",
    "    'Semnan': '20', 'Yazd': '21', 'Hormozgan': '22', 'Tehran': '23', 'Ardebil': '24', \n",
    "    'Qom': '25', 'Qazvin': '26', 'Golestan': '27', 'KhorasanShomali': '28', \n",
    "    'KhorasanJonorbi': '29', 'Alborz': '30'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  province province_encoded\n",
      "0  Markazi               00\n",
      "1  Markazi               00\n",
      "2  Markazi               00\n",
      "3  Markazi               00\n",
      "4  Markazi               00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17596\\194548099.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  U98Data_cleaned['province_encoded'] = U98Data_cleaned['province'].map(province_encoding)\n"
     ]
    }
   ],
   "source": [
    "# انکود کردن ستون province با استفاده از دیکشنری\n",
    "U98Data_cleaned['province_encoded'] = U98Data_cleaned['province'].map(province_encoding)\n",
    "\n",
    "# بررسی نتیجه\n",
    "print(U98Data_cleaned[['province', 'province_encoded']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مقادیر منحصر به فرد در ستون province_encoded:\n",
      "['00' '01' '02' '03' '04' '05' nan '07' '08' '10' '12' '13' '14' '15' '16'\n",
      " '19' '20' '21' '22' '23' '24' '25' '26' '27' '28' '30']\n"
     ]
    }
   ],
   "source": [
    "unique_provinces = U98Data_cleaned['province_encoded'].unique()\n",
    "print(\"مقادیر منحصر به فرد در ستون province_encoded:\")\n",
    "print(unique_provinces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98Data_cleaned = U98Data_cleaned.drop(columns=['province'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تعداد داده‌های پرت در ستون weight: 626\n",
      "تعداد داده‌های پرت در ستون khanevartype: 17\n",
      "تعداد داده‌های پرت در ستون town: 847\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# بررسی داده‌های پرت بر اساس IQr\n",
    "for column in nrmerical_columns:\n",
    "    Q1 = U98Data_cleaned[column].quantile(0.25)\n",
    "    Q3 = U98Data_cleaned[column].quantile(0.75)\n",
    "    IQr = Q3 - Q1\n",
    "    ortliers = ((U98Data_cleaned[column] < (Q1 - 1.5 * IQr)) | (U98Data_cleaned[column] > (Q3 + 1.5 * IQr))).sum()\n",
    "    if ortliers > 0:\n",
    "        print(f\"تعداد داده‌های پرت در ستون {column}: {ortliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# محاسبه IQr و اعمال بازه‌بندی (Capping)\n",
    "for column in ['weight']:\n",
    "    Q1 = U98Data_cleaned[column].quantile(0.25)\n",
    "    Q3 = U98Data_cleaned[column].quantile(0.75)\n",
    "    IQr = Q3 - Q1\n",
    "    \n",
    "    lower_bornd = Q1 - 1.5 * IQr\n",
    "    rpper_bornd = Q3 + 1.5 * IQr\n",
    "    \n",
    "    # اعمال بازه‌بندی\n",
    "    U98Data_cleaned[column] = np.where(U98Data_cleaned[column] < lower_bornd, lower_bornd, U98Data_cleaned[column])\n",
    "    U98Data_cleaned[column] = np.where(U98Data_cleaned[column] > rpper_bornd, rpper_bornd, U98Data_cleaned[column])\n",
    "    \n",
    "    # اعمال تبدیل لگاریتمی برای مقادیر مثبت\n",
    "    U98Data_cleaned[column] = np.log1p(U98Data_cleaned[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# جایگزینی مقادیر پرت با Mode (پرتکرارترین مقدار)\n",
    "def replace_ortliers_with_mode(column, threshold=0.01):\n",
    "    mode = U98Data_cleaned[column].mode()[0]\n",
    "    \n",
    "    # شناسایی دسته‌های نادر (کمتر از آستانه threshold)\n",
    "    value_counts = U98Data_cleaned[column].value_counts(normalize=True)\n",
    "    rare_valres = value_counts[value_counts < threshold].index\n",
    "    \n",
    "    # جایگزینی مقادیر نادر با Mode\n",
    "    U98Data_cleaned[column] = U98Data_cleaned[column].apply(lambda x: mode if x in rare_valres else x)\n",
    "\n",
    "# اعمال جایگزینی با Mode برای ستون‌های دسته‌ای\n",
    "for column in ['khanevartype', 'Takmil', 'town']:\n",
    "    replace_ortliers_with_mode(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# بررسی و اصلاح اوت‌لیرهای نادرست در ستون‌های MahMorajeh و Fasl\n",
    "# برای ماه محدوده باید بین 1 تا 12 باشد و برای فصل باید بین 1 تا 4 باشد\n",
    "def fix_invalid_valres(column, valid_range):\n",
    "    U98Data_cleaned[column] = np.where(~U98Data_cleaned[column].isin(valid_range), np.nan, U98Data_cleaned[column])\n",
    "\n",
    "# اعمال اصلاح برای ستون‌های MahMorajeh و Fasl\n",
    "fix_invalid_valres('MahMorajeh', range(1, 13))  # ماه‌ها باید بین 1 تا 12 باشند\n",
    "fix_invalid_valres('Fasl', range(1, 5))  # فصل‌ها باید بین 1 تا 4 باشند\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  9 10 11 12 13  8 14 16]\n"
     ]
    }
   ],
   "source": [
    "unique_valres = U98Data_cleaned['town'].unique()\n",
    "print(unique_valres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "unique_valres = U98Data_cleaned['Takmil'].unique()\n",
    "print(unique_valres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19898 entries, 0 to 19897\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Address           19898 non-null  int64  \n",
      " 1   MahMorajeh        19898 non-null  float64\n",
      " 2   Fasl              19898 non-null  float64\n",
      " 3   weight            19898 non-null  float64\n",
      " 4   khanevartype      19898 non-null  int64  \n",
      " 5   Takmil            19898 non-null  int64  \n",
      " 6   town              19898 non-null  int64  \n",
      " 7   province_encoded  15975 non-null  object \n",
      "dtypes: float64(3), int64(4), object(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "U98Data_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Address', 'member', 'relation', 'gender', 'age', 'literacy',\n",
       "       'studying', 'degree', 'occupationalst', 'maritalst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U98P1.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address            0.000000\n",
       "member             0.000000\n",
       "relation           0.000000\n",
       "gender             0.000000\n",
       "age                0.000000\n",
       "literacy           8.936918\n",
       "studying          19.553081\n",
       "degree            19.554546\n",
       "occupationalst    15.344714\n",
       "maritalst         15.344714\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P1.isnull().sum() / len(U98P1) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تعداد ردیف‌های تکراری: 0\n"
     ]
    }
   ],
   "source": [
    "# بررسی وجود داده‌های تکراری\n",
    "drplicate_rows = U98P1.duplicated().sum()\n",
    "print(f\"تعداد ردیف‌های تکراری: {drplicate_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های دسته‌بندی‌شده:\n",
      "Index(['relation', 'gender', 'literacy', 'studying', 'degree',\n",
      "       'occupationalst', 'maritalst'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# بررسی ستون‌های دسته‌بندی‌شده (غیر عددی)\n",
    "categorical_columns = U98P1.select_dtypes(include=['object']).columns\n",
    "print(\"ستون‌های دسته‌بندی‌شده:\")\n",
    "print(categorical_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مقادیر یونیک در ستون 'relation':\n",
      "['Head' 'Spouse' 'Child' 'GrandSonDaughter' 'SonDaughter_inLaw' 'Parent'\n",
      " 'Sibling' 'NonRelative' 'OtherRelative']\n",
      "--------------------------------------------------\n",
      "مقادیر یونیک در ستون 'gender':\n",
      "['Male' 'Female']\n",
      "--------------------------------------------------\n",
      "مقادیر یونیک در ستون 'literacy':\n",
      "['literate' nan 'illiterate']\n",
      "--------------------------------------------------\n",
      "مقادیر یونیک در ستون 'studying':\n",
      "['No' 'Yes' nan]\n",
      "--------------------------------------------------\n",
      "مقادیر یونیک در ستون 'degree':\n",
      "['Diploma' 'College' 'Elemantry' 'Secondary' nan 'Master' 'Bachelor'\n",
      " 'HighSchool' 'PhD' 'Other']\n",
      "--------------------------------------------------\n",
      "مقادیر یونیک در ستون 'occupationalst':\n",
      "['IncomeWOJob' 'employed' 'Housewife' 'Student' nan 'unemployed' 'Other']\n",
      "--------------------------------------------------\n",
      "مقادیر یونیک در ستون 'maritalst':\n",
      "['Married' 'Single' nan 'Widowed' 'Divorced']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# لیست ستون‌های دسته‌بندی‌شده\n",
    "categorical_columns = ['relation', 'gender', 'literacy', 'studying', 'degree', 'occupationalst', 'maritalst']\n",
    "\n",
    "# حلقه برای مشاهده داده‌های یونیک در هر ستون\n",
    "for column in categorical_columns:\n",
    "    unique_valres = U98P1[column].unique()\n",
    "    print(f\"مقادیر یونیک در ستون '{column}':\")\n",
    "    print(unique_valres)\n",
    "    print(\"-\" * 50)  # جداکننده برای خوانایی بیشتر\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# دیکشنری‌های انکودینگ\n",
    "relation_encoding = {\n",
    "    'Head': '1', 'Sporse': '2', 'Child': '3', 'SonDarghter_inLaw': '4', \n",
    "    'GrandSonDarghter': '5', 'Parent': '6', 'Sibling': '7', 'Otherrelative': '8', \n",
    "    'Nonrelative': '9'\n",
    "}\n",
    "\n",
    "gender_encoding = {'Male': '1', 'Female': '2'}\n",
    "\n",
    "literacy_encoding = {'literate': '1', 'illiterate': '2'}\n",
    "\n",
    "yesno_encoding = {'Yes': '1', 'No': '2'}\n",
    "\n",
    "edrcation_encoding = {\n",
    "    'Elemantry': '1', 'Secondary': '2', 'HighSchool': '3', 'Diploma': '4', \n",
    "    'College': '5', 'Bachelor': '6', 'Master': '7', 'PhD': '8', 'Other': '9'\n",
    "}\n",
    "\n",
    "occrpation_encoding = {\n",
    "    'employed': '1', 'rnemployed': '2', 'IncomeWOJob': '3', 'Strdent': '4', \n",
    "    'Horsewife': '5', 'Other': '6'\n",
    "}\n",
    "\n",
    "marital_encoding = {'Married': '1', 'Widowed': '2', 'Divorced': '3', 'Single': '4'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "U98P1['relation_encoded'] = U98P1['relation'].map(relation_encoding)\n",
    "U98P1['gender_encoded'] = U98P1['gender'].map(gender_encoding)\n",
    "U98P1['literacy_encoded'] = U98P1['literacy'].map(literacy_encoding)\n",
    "U98P1['studying_encoded'] = U98P1['studying'].map(yesno_encoding)\n",
    "U98P1['degree_encoded'] = U98P1['degree'].map(edrcation_encoding)\n",
    "U98P1['occupationalst_encoded'] = U98P1['occupationalst'].map(occrpation_encoding)\n",
    "U98P1['maritalst_encoded'] = U98P1['maritalst'].map(marital_encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98P1 = U98P1.drop(columns=['relation', 'gender', 'literacy', 'studying', 'degree', 'occupationalst', 'maritalst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>member</th>\n",
       "      <th>age</th>\n",
       "      <th>relation_encoded</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>literacy_encoded</th>\n",
       "      <th>studying_encoded</th>\n",
       "      <th>degree_encoded</th>\n",
       "      <th>occupationalst_encoded</th>\n",
       "      <th>maritalst_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10004004223</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10004004223</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004004220</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004004220</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004004220</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Address  member  age relation_encoded gender_encoded literacy_encoded  \\\n",
       "0  10004004223       1   66                1              1                1   \n",
       "1  10004004223       2   61              NaN              2                1   \n",
       "2  10004004220       1   36                1              1                1   \n",
       "3  10004004220       2   33              NaN              2                1   \n",
       "4  10004004220       3   12                3              2                1   \n",
       "\n",
       "  studying_encoded degree_encoded occupationalst_encoded maritalst_encoded  \n",
       "0                2              4                      3                 1  \n",
       "1                2              5                      3                 1  \n",
       "2                2              1                      1                 1  \n",
       "3                2              2                    NaN                 1  \n",
       "4                1              1                    NaN                 4  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U98P1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "نوع داده‌های هر ستون:\n",
      "Address                    int64\n",
      "member                     int64\n",
      "age                        int64\n",
      "relation_encoded          object\n",
      "gender_encoded            object\n",
      "literacy_encoded          object\n",
      "studying_encoded          object\n",
      "degree_encoded            object\n",
      "occupationalst_encoded    object\n",
      "maritalst_encoded         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# نمایش نوع داده‌ها برای هر ستون\n",
    "print(\"نوع داده‌های هر ستون:\")\n",
    "print(U98P1.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مقادیر یونیک در ستون 'relation_encoded': ['1' nan '3' '6' '7']\n",
      "مقادیر یونیک در ستون 'gender_encoded': ['1' '2']\n",
      "مقادیر یونیک در ستون 'literacy_encoded': ['1' nan '2']\n",
      "مقادیر یونیک در ستون 'studying_encoded': ['2' '1' nan]\n",
      "مقادیر یونیک در ستون 'degree_encoded': ['4' '5' '1' '2' nan '7' '6' '3' '8' '9']\n",
      "مقادیر یونیک در ستون 'occupationalst_encoded': ['3' '1' nan '6']\n",
      "مقادیر یونیک در ستون 'maritalst_encoded': ['1' '4' nan '2' '3']\n"
     ]
    }
   ],
   "source": [
    "# بررسی مقادیر یونیک در هر ستون انکود شده\n",
    "print(\"مقادیر یونیک در ستون 'relation_encoded':\", U98P1['relation_encoded'].unique())\n",
    "print(\"مقادیر یونیک در ستون 'gender_encoded':\", U98P1['gender_encoded'].unique())\n",
    "print(\"مقادیر یونیک در ستون 'literacy_encoded':\", U98P1['literacy_encoded'].unique())\n",
    "print(\"مقادیر یونیک در ستون 'studying_encoded':\", U98P1['studying_encoded'].unique())\n",
    "print(\"مقادیر یونیک در ستون 'degree_encoded':\", U98P1['degree_encoded'].unique())\n",
    "print(\"مقادیر یونیک در ستون 'occupationalst_encoded':\", U98P1['occupationalst_encoded'].unique())\n",
    "print(\"مقادیر یونیک در ستون 'maritalst_encoded':\", U98P1['maritalst_encoded'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = U98P1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# بررسی ستون‌ها و جدا کردن داده‌های مفقود و غیر مفقود\n",
    "df_not_null = df_encoded[df_encoded['studying_encoded'].notnull()]\n",
    "df_null = df_encoded[df_encoded['studying_encoded'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_not_null.drop(['studying_encoded'], axis=1)\n",
    "y = df_not_null['studying_encoded']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9686731627356343\n",
      "recall: 0.9266755142667551\n",
      "F1 Score: 0.9419898819561552\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "y_test_nrmeric = y_test.astype(int)\n",
    "y_pred_nrmeric = y_pred.astype(int)\n",
    "\n",
    "# محاسبه دقت (accuracy)\n",
    "accuracy = accuracy_score(y_test_nrmeric, y_pred_nrmeric)\n",
    "print(f'accuracy: {accuracy}')\n",
    "\n",
    "# محاسبه recall و F1 Score\n",
    "recall = recall_score(y_test_nrmeric, y_pred_nrmeric)\n",
    "f1 = f1_score(y_test_nrmeric, y_pred_nrmeric)\n",
    "\n",
    "print(f'recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Address  member  age relation_encoded gender_encoded literacy_encoded  \\\n",
      "0  10004004223       1   66                1              1                1   \n",
      "1  10004004223       2   61              NaN              2                1   \n",
      "2  10004004220       1   36                1              1                1   \n",
      "3  10004004220       2   33              NaN              2                1   \n",
      "4  10004004220       3   12                3              2                1   \n",
      "\n",
      "  studying_encoded degree_encoded occupationalst_encoded maritalst_encoded  \n",
      "0                2              4                      3                 1  \n",
      "1                2              5                      3                 1  \n",
      "2                2              1                      1                 1  \n",
      "3                2              2                    NaN                 1  \n",
      "4                1              1                    NaN                 4  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_null = df_null.drop(['studying_encoded'], axis=1)\n",
    "\n",
    "\n",
    "df_null.loc[:, 'studying_encoded'] = model.predict(X_null)\n",
    "\n",
    "\n",
    "U98P1_filled = pd.concat([df_not_null, df_null])\n",
    "\n",
    "\n",
    "U98P1_filled.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "print(U98P1_filled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address                    0.000000\n",
       "member                     0.000000\n",
       "age                        0.000000\n",
       "relation_encoded          26.190930\n",
       "gender_encoded             0.000000\n",
       "literacy_encoded           8.936918\n",
       "studying_encoded           0.000000\n",
       "degree_encoded            19.554546\n",
       "occupationalst_encoded    61.239651\n",
       "maritalst_encoded         15.344714\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P1_filled.isnull().sum() / len(U98P1) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded2 = U98P1_filled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9686731627356343\n",
      "       Address  member  age relation_encoded gender_encoded literacy_encoded  \\\n",
      "0  10004004223       1   66                1              1                1   \n",
      "1  10004004223       2   61              NaN              2                1   \n",
      "2  10004004220       1   36                1              1                1   \n",
      "3  10004004220       2   33              NaN              2                1   \n",
      "4  10004004220       3   12                3              2                1   \n",
      "\n",
      "  studying_encoded degree_encoded occupationalst_encoded maritalst_encoded  \n",
      "0                2              4                      3                 1  \n",
      "1                2              5                      3                 1  \n",
      "2                2              1                      1                 1  \n",
      "3                2              2                    NaN                 1  \n",
      "4                1              1                    NaN                 4  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_not_null = df_encoded2[df_encoded2['literacy_encoded'].notnull()]\n",
    "df_null = df_encoded2[df_encoded2['literacy_encoded'].isnull()]\n",
    "\n",
    "\n",
    "X = df_not_null.drop(['literacy_encoded'], axis=1)\n",
    "y = df_not_null['literacy_encoded']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test_nrmeric, y_pred_nrmeric)\n",
    "print(f'accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_null = df_null.drop(['literacy_encoded'], axis=1)\n",
    "\n",
    "\n",
    "df_null.loc[:, 'literacy_encoded'] = model.predict(X_null)\n",
    "\n",
    "\n",
    "U98P1_filled = pd.concat([df_not_null, df_null])\n",
    "\n",
    "\n",
    "U98P1_filled.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "print(U98P1_filled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address                    0.000000\n",
       "member                     0.000000\n",
       "age                        0.000000\n",
       "relation_encoded          26.190930\n",
       "gender_encoded             0.000000\n",
       "literacy_encoded           0.000000\n",
       "studying_encoded           0.000000\n",
       "degree_encoded            19.554546\n",
       "occupationalst_encoded    61.239651\n",
       "maritalst_encoded         15.344714\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P1_filled.isnull().sum() / len(U98P1) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded3 = U98P1_filled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for degree_encoded: 0.43306010928961747\n",
      "       Address  member  age relation_encoded gender_encoded literacy_encoded  \\\n",
      "0  10004004223       1   66                1              1                1   \n",
      "1  10004004223       2   61              NaN              2                1   \n",
      "2  10004004220       1   36                1              1                1   \n",
      "3  10004004220       2   33              NaN              2                1   \n",
      "4  10004004220       3   12                3              2                1   \n",
      "\n",
      "  studying_encoded degree_encoded occupationalst_encoded maritalst_encoded  \n",
      "0                2              4                      3                 1  \n",
      "1                2              5                      3                 1  \n",
      "2                2              1                      1                 1  \n",
      "3                2              2                    NaN                 1  \n",
      "4                1              1                    NaN                 4  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_not_null = df_encoded3[df_encoded3['degree_encoded'].notnull()]\n",
    "df_null = df_encoded3[df_encoded3['degree_encoded'].isnull()]\n",
    "\n",
    "\n",
    "X = df_not_null.drop(['degree_encoded'], axis=1)\n",
    "y = df_not_null['degree_encoded']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(f'accuracy for degree_encoded: {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "\n",
    "X_null = df_null.drop(['degree_encoded'], axis=1)\n",
    "\n",
    "\n",
    "df_null.loc[:, 'degree_encoded'] = model.predict(X_null)\n",
    "\n",
    "\n",
    "U98P1_filled = pd.concat([df_not_null, df_null])\n",
    "\n",
    "\n",
    "U98P1_filled.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "print(U98P1_filled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address                    0.000000\n",
       "member                     0.000000\n",
       "age                        0.000000\n",
       "relation_encoded          26.190930\n",
       "gender_encoded             0.000000\n",
       "literacy_encoded           0.000000\n",
       "studying_encoded           0.000000\n",
       "degree_encoded             0.000000\n",
       "occupationalst_encoded    61.239651\n",
       "maritalst_encoded         15.344714\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P1_filled.isnull().sum() / len(U98P1) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded4 = U98P1_filled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for occupationalst_encoded : 0.8178038178038178\n",
      "       Address  member  age relation_encoded gender_encoded literacy_encoded  \\\n",
      "0  10004004223       1   66                1              1                1   \n",
      "1  10004004223       2   61              NaN              2                1   \n",
      "2  10004004220       1   36                1              1                1   \n",
      "3  10004004220       2   33              NaN              2                1   \n",
      "4  10004004220       3   12                3              2                1   \n",
      "\n",
      "  studying_encoded degree_encoded occupationalst_encoded maritalst_encoded  \n",
      "0                2              4                      3                 1  \n",
      "1                2              5                      3                 1  \n",
      "2                2              1                      1                 1  \n",
      "3                2              2                      1                 1  \n",
      "4                1              1                      1                 4  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_not_null = df_encoded4[df_encoded4['occupationalst_encoded'].notnull()]\n",
    "df_null = df_encoded4[df_encoded4['occupationalst_encoded'].isnull()]\n",
    "\n",
    "\n",
    "X = df_not_null.drop(['occupationalst_encoded'], axis=1)\n",
    "y = df_not_null['occupationalst_encoded']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(f'accuracy for occupationalst_encoded : {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "\n",
    "X_null = df_null.drop(['occupationalst_encoded'], axis=1)\n",
    "\n",
    "\n",
    "df_null.loc[:, 'occupationalst_encoded'] = model.predict(X_null)\n",
    "\n",
    "\n",
    "U98P1_filled = pd.concat([df_not_null, df_null])\n",
    "\n",
    "\n",
    "U98P1_filled.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "print(U98P1_filled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address                    0.000000\n",
       "member                     0.000000\n",
       "age                        0.000000\n",
       "relation_encoded          26.190930\n",
       "gender_encoded             0.000000\n",
       "literacy_encoded           0.000000\n",
       "studying_encoded           0.000000\n",
       "degree_encoded             0.000000\n",
       "occupationalst_encoded     0.000000\n",
       "maritalst_encoded         15.344714\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P1_filled.isnull().sum() / len(U98P1) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded5 = U98P1_filled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for maritalst_encoded : 0.9393336218087408\n",
      "       Address  member  age relation_encoded gender_encoded literacy_encoded  \\\n",
      "0  10004004223       1   66                1              1                1   \n",
      "1  10004004223       2   61              NaN              2                1   \n",
      "2  10004004220       1   36                1              1                1   \n",
      "3  10004004220       2   33              NaN              2                1   \n",
      "4  10004004220       3   12                3              2                1   \n",
      "\n",
      "  studying_encoded degree_encoded occupationalst_encoded maritalst_encoded  \n",
      "0                2              4                      3                 1  \n",
      "1                2              5                      3                 1  \n",
      "2                2              1                      1                 1  \n",
      "3                2              2                      1                 1  \n",
      "4                1              1                      1                 4  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_not_null = df_encoded5[df_encoded5['maritalst_encoded'].notnull()]\n",
    "df_null = df_encoded5[df_encoded5['maritalst_encoded'].isnull()]\n",
    "\n",
    "\n",
    "X = df_not_null.drop(['maritalst_encoded'], axis=1)\n",
    "y = df_not_null['maritalst_encoded']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(f'Accuracy for maritalst_encoded : {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "\n",
    "X_null = df_null.drop(['maritalst_encoded'], axis=1)\n",
    "\n",
    "\n",
    "df_null.loc[:, 'maritalst_encoded'] = model.predict(X_null)\n",
    "\n",
    "\n",
    "U98P1_filled = pd.concat([df_not_null, df_null])\n",
    "\n",
    "\n",
    "U98P1_filled.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "print(U98P1_filled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address       0.000000\n",
       "code          0.000000\n",
       "purchased     0.000000\n",
       "gram         75.107494\n",
       "kilogram     24.423785\n",
       "price         8.941440\n",
       "value         0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S01.isnull().sum() / len(U98P3S01) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98P3S01_cleaned = U98P3S01.dropna(subset=['price', 'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17596\\1060726189.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  U98P3S01_cleaned['calculated_amount'] = U98P3S01_cleaned['value'] / U98P3S01_cleaned['price']\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17596\\1060726189.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  U98P3S01_cleaned['calculated_kg'] = U98P3S01_cleaned['calculated_amount'].apply(np.floor)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17596\\1060726189.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  U98P3S01_cleaned['calculated_gram'] = (U98P3S01_cleaned['calculated_amount'] % 1) * 1000\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17596\\1060726189.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  U98P3S01_cleaned['kilogram'] = U98P3S01_cleaned['kilogram'].fillna(U98P3S01_cleaned['calculated_kg'])\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17596\\1060726189.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  U98P3S01_cleaned['gram'] = U98P3S01_cleaned['gram'].fillna(U98P3S01_cleaned['calculated_gram'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "U98P3S01_cleaned['calculated_amount'] = U98P3S01_cleaned['value'] / U98P3S01_cleaned['price']\n",
    "\n",
    "\n",
    "U98P3S01_cleaned['calculated_kg'] = U98P3S01_cleaned['calculated_amount'].apply(np.floor)\n",
    "U98P3S01_cleaned['calculated_gram'] = (U98P3S01_cleaned['calculated_amount'] % 1) * 1000\n",
    "\n",
    "\n",
    "U98P3S01_cleaned['kilogram'] = U98P3S01_cleaned['kilogram'].fillna(U98P3S01_cleaned['calculated_kg'])\n",
    "U98P3S01_cleaned['gram'] = U98P3S01_cleaned['gram'].fillna(U98P3S01_cleaned['calculated_gram'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address              0.0\n",
       "code                 0.0\n",
       "purchased            0.0\n",
       "gram                 0.0\n",
       "kilogram             0.0\n",
       "price                0.0\n",
       "value                0.0\n",
       "calculated_amount    0.0\n",
       "calculated_kg        0.0\n",
       "calculated_gram      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S01_cleaned.isnull().sum() / len(U98P3S01_cleaned) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های عددی:\n",
      "Index(['Address', 'code', 'purchased', 'kilogram', 'price', 'value',\n",
      "       'calculated_amount', 'calculated_kg', 'calculated_gram'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "numerical_columns = U98P3S01_cleaned.select_dtypes(include=['number']).columns\n",
    "print(\"ستون‌های عددی:\")\n",
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address        0.000000\n",
       "code           0.000000\n",
       "purchased      0.000000\n",
       "gram         100.000000\n",
       "kilogram      16.177256\n",
       "price         16.203951\n",
       "value          0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S02.isnull().sum() / len(U98P3S02) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98P3S02_cleaned = U98P3S02.dropna(subset=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17596\\47346988.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  U98P3S02_cleaned['calculated_amount'] = U98P3S02_cleaned['value'] / U98P3S02_cleaned['price']\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17596\\47346988.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  U98P3S02_cleaned['calculated_kg'] = U98P3S02_cleaned['calculated_amount'].apply(np.floor)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17596\\47346988.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  U98P3S02_cleaned['calculated_gram'] = (U98P3S02_cleaned['calculated_amount'] % 1) * 1000\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17596\\47346988.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  U98P3S02_cleaned['kilogram'] = U98P3S02_cleaned['kilogram'].fillna(U98P3S02_cleaned['calculated_kg'])\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17596\\47346988.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  U98P3S02_cleaned['gram'] = U98P3S02_cleaned['gram'].fillna(U98P3S02_cleaned['calculated_gram'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "U98P3S02_cleaned['calculated_amount'] = U98P3S02_cleaned['value'] / U98P3S02_cleaned['price']\n",
    "\n",
    "\n",
    "U98P3S02_cleaned['calculated_kg'] = U98P3S02_cleaned['calculated_amount'].apply(np.floor)\n",
    "U98P3S02_cleaned['calculated_gram'] = (U98P3S02_cleaned['calculated_amount'] % 1) * 1000\n",
    "\n",
    "\n",
    "U98P3S02_cleaned['kilogram'] = U98P3S02_cleaned['kilogram'].fillna(U98P3S02_cleaned['calculated_kg'])\n",
    "U98P3S02_cleaned['gram'] = U98P3S02_cleaned['gram'].fillna(U98P3S02_cleaned['calculated_gram'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address              0.0\n",
       "code                 0.0\n",
       "purchased            0.0\n",
       "gram                 0.0\n",
       "kilogram             0.0\n",
       "price                0.0\n",
       "value                0.0\n",
       "calculated_amount    0.0\n",
       "calculated_kg        0.0\n",
       "calculated_gram      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S01_cleaned.isnull().sum() / len(U98P3S01_cleaned) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های عددی:\n",
      "Index(['Address', 'code', 'purchased', 'kilogram', 'price', 'value',\n",
      "       'calculated_amount', 'calculated_kg', 'calculated_gram'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "numerical_columns = U98P3S01_cleaned.select_dtypes(include=['number']).columns\n",
    "print(\"ستون‌های عددی:\")\n",
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address        0.000000\n",
       "code           0.000000\n",
       "purchased      0.000000\n",
       "gram         100.000000\n",
       "kilogram      16.177256\n",
       "price         16.203951\n",
       "value          0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S02.isnull().sum() / len(U98P3S02) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98P3S02_cleaned = U98P3S02.dropna(subset=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17596\\47346988.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  U98P3S02_cleaned['calculated_amount'] = U98P3S02_cleaned['value'] / U98P3S02_cleaned['price']\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17596\\47346988.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  U98P3S02_cleaned['calculated_kg'] = U98P3S02_cleaned['calculated_amount'].apply(np.floor)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17596\\47346988.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  U98P3S02_cleaned['calculated_gram'] = (U98P3S02_cleaned['calculated_amount'] % 1) * 1000\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17596\\47346988.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  U98P3S02_cleaned['kilogram'] = U98P3S02_cleaned['kilogram'].fillna(U98P3S02_cleaned['calculated_kg'])\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17596\\47346988.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  U98P3S02_cleaned['gram'] = U98P3S02_cleaned['gram'].fillna(U98P3S02_cleaned['calculated_gram'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "U98P3S02_cleaned['calculated_amount'] = U98P3S02_cleaned['value'] / U98P3S02_cleaned['price']\n",
    "\n",
    "\n",
    "U98P3S02_cleaned['calculated_kg'] = U98P3S02_cleaned['calculated_amount'].apply(np.floor)\n",
    "U98P3S02_cleaned['calculated_gram'] = (U98P3S02_cleaned['calculated_amount'] % 1) * 1000\n",
    "\n",
    "\n",
    "U98P3S02_cleaned['kilogram'] = U98P3S02_cleaned['kilogram'].fillna(U98P3S02_cleaned['calculated_kg'])\n",
    "U98P3S02_cleaned['gram'] = U98P3S02_cleaned['gram'].fillna(U98P3S02_cleaned['calculated_gram'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address              0.0\n",
       "code                 0.0\n",
       "purchased            0.0\n",
       "gram                 0.0\n",
       "kilogram             0.0\n",
       "price                0.0\n",
       "value                0.0\n",
       "calculated_amount    0.0\n",
       "calculated_kg        0.0\n",
       "calculated_gram      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S02_cleaned.isnull().sum() / len(U98P3S02_cleaned) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address      0.0\n",
       "code         0.0\n",
       "purchased    0.0\n",
       "value        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S03.isnull().sum() / len(U98P3S03) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های دسته‌بندی‌شده:\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = U98P3S03.select_dtypes(include=['object']).columns\n",
    "print(\"ستون‌های دسته‌بندی‌شده:\")\n",
    "print(categorical_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates = U98P3S03.duplicated().sum()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = U98P3S03.select_dtypes(include=['object']).columns\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های عددی:\n",
      "Index(['Address', 'code', 'purchased', 'value'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "numerical_columns = U98P3S03.select_dtypes(include=['number']).columns\n",
    "print(\"ستون‌های عددی:\")\n",
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تعداد داده‌های پرت در ستون code: 4946\n",
      "تعداد داده‌های پرت در ستون purchased: 112\n",
      "تعداد داده‌های پرت در ستون value: 1527\n"
     ]
    }
   ],
   "source": [
    "# بررسی داده‌های پرت بر اساس IQR\n",
    "for column in numerical_columns:\n",
    "    Q1 = U98P3S03[column].quantile(0.25)\n",
    "    Q3 = U98P3S03[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((U98P3S03[column] < (Q1 - 1.5 * IQR)) | (U98P3S03[column] > (Q3 + 1.5 * IQR))).sum()\n",
    "    if outliers > 0:\n",
    "        print(f\"تعداد داده‌های پرت در ستون {column}: {outliers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address       0.000000\n",
       "code          0.000000\n",
       "mortgage     95.953623\n",
       "purchased    16.124058\n",
       "value         0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S04.isnull().sum() / len(U98P3S04) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98P3S04_cleaned = U98P3S04.dropna(subset=['mortgage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address      0.0\n",
       "code         0.0\n",
       "mortgage     0.0\n",
       "purchased    0.0\n",
       "value        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S04_cleaned.isnull().sum() / len(U98P3S04_cleaned) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates = U98P3S04_cleaned.duplicated().sum()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های دسته‌بندی‌شده:\n",
      "Index(['mortgage', 'purchased'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = U98P3S04_cleaned.select_dtypes(include=['object']).columns\n",
    "print(\"ستون‌های دسته‌بندی‌شده:\")\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های عددی:\n",
      "Index(['Address', 'code', 'value'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "numerical_columns = U98P3S04_cleaned.select_dtypes(include=['number']).columns\n",
    "print(\"ستون‌های عددی:\")\n",
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تعداد داده‌های پرت در ستون code: 1\n",
      "تعداد داده‌های پرت در ستون value: 350\n"
     ]
    }
   ],
   "source": [
    "# بررسی داده‌های پرت بر اساس IQR\n",
    "for column in numerical_columns:\n",
    "    Q1 = U98P3S04_cleaned[column].quantile(0.25)\n",
    "    Q3 = U98P3S04_cleaned[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((U98P3S04_cleaned[column] < (Q1 - 1.5 * IQR)) | (U98P3S04_cleaned[column] > (Q3 + 1.5 * IQR))).sum()\n",
    "    if outliers > 0:\n",
    "        print(f\"تعداد داده‌های پرت در ستون {column}: {outliers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address      0.0\n",
       "code         0.0\n",
       "purchased    0.0\n",
       "value        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S05.isnull().sum() / len(U98P3S05) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = U98P3S05.duplicated().sum()\n",
    "duplicates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های دسته‌بندی‌شده:\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "categorical_columns = U98P3S05.select_dtypes(include=['object']).columns\n",
    "print(\"ستون‌های دسته‌بندی‌شده:\")\n",
    "print(categorical_columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های عددی:\n",
      "Index(['Address', 'code', 'purchased', 'value'], dtype='object')\n",
      "تعداد داده‌های پرت در ستون code: 28021\n",
      "تعداد داده‌های پرت در ستون purchased: 1237\n",
      "تعداد داده‌های پرت در ستون value: 6148\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "numerical_columns = U98P3S05.select_dtypes(include=['number']).columns\n",
    "print(\"ستون‌های عددی:\")\n",
    "print(numerical_columns)\n",
    "# بررسی داده‌های پرت بر اساس IQR\n",
    "for column in numerical_columns:\n",
    "    Q1 = U98P3S05[column].quantile(0.25)\n",
    "    Q3 = U98P3S05[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((U98P3S05[column] < (Q1 - 1.5 * IQR)) | (U98P3S05[column] > (Q3 + 1.5 * IQR))).sum()\n",
    "    if outliers > 0:\n",
    "        print(f\"تعداد داده‌های پرت در ستون {column}: {outliers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address      0.0\n",
       "code         0.0\n",
       "purchased    0.0\n",
       "value        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S06.isnull().sum() / len(U98P3S06) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ستون‌های دسته‌بندی‌شده:\n",
      "Index([], dtype='object')\n",
      "ستون‌های عددی:\n",
      "Index(['Address', 'code', 'purchased', 'value'], dtype='object')\n",
      "تعداد داده‌های پرت در ستون code: 26\n",
      "تعداد داده‌های پرت در ستون purchased: 3755\n",
      "تعداد داده‌های پرت در ستون value: 3947\n"
     ]
    }
   ],
   "source": [
    "duplicates = U98P3S06.duplicated().sum()\n",
    "print(duplicates)\n",
    "categorical_columns = U98P3S06.select_dtypes(include=['object']).columns\n",
    "print(\"ستون‌های دسته‌بندی‌شده:\")\n",
    "print(categorical_columns)\n",
    "\n",
    "numerical_columns = U98P3S06.select_dtypes(include=['number']).columns\n",
    "print(\"ستون‌های عددی:\")\n",
    "print(numerical_columns)\n",
    "# بررسی داده‌های پرت بر اساس IQR\n",
    "for column in numerical_columns:\n",
    "    Q1 = U98P3S06[column].quantile(0.25)\n",
    "    Q3 = U98P3S06[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((U98P3S06[column] < (Q1 - 1.5 * IQR)) | (U98P3S06[column] > (Q3 + 1.5 * IQR))).sum()\n",
    "    if outliers > 0:\n",
    "        print(f\"تعداد داده‌های پرت در ستون {column}: {outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address      0.0\n",
       "code         0.0\n",
       "purchased    0.0\n",
       "value        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S07.isnull().sum() / len(U98P3S07) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates = U98P3S07.duplicated().sum()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های دسته‌بندی‌شده:\n",
      "Index([], dtype='object')\n",
      "ستون‌های عددی:\n",
      "Index(['Address', 'code', 'purchased', 'value'], dtype='object')\n",
      "تعداد داده‌های پرت در ستون purchased: 180\n",
      "تعداد داده‌های پرت در ستون value: 3357\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = U98P3S07.select_dtypes(include=['object']).columns\n",
    "print(\"ستون‌های دسته‌بندی‌شده:\")\n",
    "print(categorical_columns)\n",
    "\n",
    "numerical_columns = U98P3S07.select_dtypes(include=['number']).columns\n",
    "print(\"ستون‌های عددی:\")\n",
    "print(numerical_columns)\n",
    "# بررسی داده‌های پرت بر اساس IQR\n",
    "for column in numerical_columns:\n",
    "    Q1 = U98P3S07[column].quantile(0.25)\n",
    "    Q3 = U98P3S07[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((U98P3S07[column] < (Q1 - 1.5 * IQR)) | (U98P3S07[column] > (Q3 + 1.5 * IQR))).sum()\n",
    "    if outliers > 0:\n",
    "        print(f\"تعداد داده‌های پرت در ستون {column}: {outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address      0.0\n",
       "code         0.0\n",
       "purchased    0.0\n",
       "value        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S05.isnull().sum() / len(U98P3S05) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = U98P3S05.duplicated().sum()\n",
    "duplicates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های دسته‌بندی‌شده:\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "categorical_columns = U98P3S05.select_dtypes(include=['object']).columns\n",
    "print(\"ستون‌های دسته‌بندی‌شده:\")\n",
    "print(categorical_columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های عددی:\n",
      "Index(['Address', 'code', 'purchased', 'value'], dtype='object')\n",
      "تعداد داده‌های پرت در ستون code: 28021\n",
      "تعداد داده‌های پرت در ستون purchased: 1237\n",
      "تعداد داده‌های پرت در ستون value: 6148\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "numerical_columns = U98P3S05.select_dtypes(include=['number']).columns\n",
    "print(\"ستون‌های عددی:\")\n",
    "print(numerical_columns)\n",
    "# بررسی داده‌های پرت بر اساس IQR\n",
    "for column in numerical_columns:\n",
    "    Q1 = U98P3S05[column].quantile(0.25)\n",
    "    Q3 = U98P3S05[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((U98P3S05[column] < (Q1 - 1.5 * IQR)) | (U98P3S05[column] > (Q3 + 1.5 * IQR))).sum()\n",
    "    if outliers > 0:\n",
    "        print(f\"تعداد داده‌های پرت در ستون {column}: {outliers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address      0.0\n",
       "code         0.0\n",
       "purchased    0.0\n",
       "value        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S06.isnull().sum() / len(U98P3S06) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ستون‌های دسته‌بندی‌شده:\n",
      "Index([], dtype='object')\n",
      "ستون‌های عددی:\n",
      "Index(['Address', 'code', 'purchased', 'value'], dtype='object')\n",
      "تعداد داده‌های پرت در ستون code: 26\n",
      "تعداد داده‌های پرت در ستون purchased: 3755\n",
      "تعداد داده‌های پرت در ستون value: 3947\n"
     ]
    }
   ],
   "source": [
    "duplicates = U98P3S06.duplicated().sum()\n",
    "print(duplicates)\n",
    "categorical_columns = U98P3S06.select_dtypes(include=['object']).columns\n",
    "print(\"ستون‌های دسته‌بندی‌شده:\")\n",
    "print(categorical_columns)\n",
    "\n",
    "numerical_columns = U98P3S06.select_dtypes(include=['number']).columns\n",
    "print(\"ستون‌های عددی:\")\n",
    "print(numerical_columns)\n",
    "# بررسی داده‌های پرت بر اساس IQR\n",
    "for column in numerical_columns:\n",
    "    Q1 = U98P3S06[column].quantile(0.25)\n",
    "    Q3 = U98P3S06[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((U98P3S06[column] < (Q1 - 1.5 * IQR)) | (U98P3S06[column] > (Q3 + 1.5 * IQR))).sum()\n",
    "    if outliers > 0:\n",
    "        print(f\"تعداد داده‌های پرت در ستون {column}: {outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address      0.0\n",
       "code         0.0\n",
       "purchased    0.0\n",
       "value        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S07.isnull().sum() / len(U98P3S07) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates = U98P3S07.duplicated().sum()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های دسته‌بندی‌شده:\n",
      "Index([], dtype='object')\n",
      "ستون‌های عددی:\n",
      "Index(['Address', 'code', 'purchased', 'value'], dtype='object')\n",
      "تعداد داده‌های پرت در ستون purchased: 180\n",
      "تعداد داده‌های پرت در ستون value: 3357\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = U98P3S07.select_dtypes(include=['object']).columns\n",
    "print(\"ستون‌های دسته‌بندی‌شده:\")\n",
    "print(categorical_columns)\n",
    "\n",
    "numerical_columns = U98P3S07.select_dtypes(include=['number']).columns\n",
    "print(\"ستون‌های عددی:\")\n",
    "print(numerical_columns)\n",
    "# بررسی داده‌های پرت بر اساس IQR\n",
    "for column in numerical_columns:\n",
    "    Q1 = U98P3S07[column].quantile(0.25)\n",
    "    Q3 = U98P3S07[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((U98P3S07[column] < (Q1 - 1.5 * IQR)) | (U98P3S07[column] > (Q3 + 1.5 * IQR))).sum()\n",
    "    if outliers > 0:\n",
    "        print(f\"تعداد داده‌های پرت در ستون {column}: {outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address      0.0\n",
       "code         0.0\n",
       "purchased    0.0\n",
       "value        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S08.isnull().sum() / len(U98P3S08) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates = U98P3S08.duplicated().sum()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های دسته‌بندی‌شده:\n",
      "Index([], dtype='object')\n",
      "ستون‌های عددی:\n",
      "Index(['Address', 'code', 'purchased', 'value'], dtype='object')\n",
      "تعداد داده‌های پرت در ستون code: 184\n",
      "تعداد داده‌های پرت در ستون purchased: 12\n",
      "تعداد داده‌های پرت در ستون value: 2892\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = U98P3S08.select_dtypes(include=['object']).columns\n",
    "print(\"ستون‌های دسته‌بندی‌شده:\")\n",
    "print(categorical_columns)\n",
    "\n",
    "numerical_columns = U98P3S08.select_dtypes(include=['number']).columns\n",
    "print(\"ستون‌های عددی:\")\n",
    "print(numerical_columns)\n",
    "# بررسی داده‌های پرت بر اساس IQR\n",
    "for column in numerical_columns:\n",
    "    Q1 = U98P3S08[column].quantile(0.25)\n",
    "    Q3 = U98P3S08[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((U98P3S08[column] < (Q1 - 1.5 * IQR)) | (U98P3S08[column] > (Q3 + 1.5 * IQR))).sum()\n",
    "    if outliers > 0:\n",
    "        print(f\"تعداد داده‌های پرت در ستون {column}: {outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address      0.0\n",
       "code         0.0\n",
       "purchased    0.0\n",
       "value        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S09.isnull().sum() / len(U98P3S09) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates = U98P3S09.duplicated().sum()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های دسته‌بندی‌شده:\n",
      "Index([], dtype='object')\n",
      "ستون‌های عددی:\n",
      "Index(['Address', 'code', 'purchased', 'value'], dtype='object')\n",
      "تعداد داده‌های پرت در ستون code: 139\n",
      "تعداد داده‌های پرت در ستون purchased: 88\n",
      "تعداد داده‌های پرت در ستون value: 1349\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = U98P3S09.select_dtypes(include=['object']).columns\n",
    "print(\"ستون‌های دسته‌بندی‌شده:\")\n",
    "print(categorical_columns)\n",
    "\n",
    "numerical_columns = U98P3S09.select_dtypes(include=['number']).columns\n",
    "print(\"ستون‌های عددی:\")\n",
    "print(numerical_columns)\n",
    "# بررسی داده‌های پرت بر اساس IQR\n",
    "for column in numerical_columns:\n",
    "    Q1 = U98P3S09[column].quantile(0.25)\n",
    "    Q3 = U98P3S09[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((U98P3S09[column] < (Q1 - 1.5 * IQR)) | (U98P3S09[column] > (Q3 + 1.5 * IQR))).sum()\n",
    "    if outliers > 0:\n",
    "        print(f\"تعداد داده‌های پرت در ستون {column}: {outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address      0.0\n",
       "code         0.0\n",
       "purchased    0.0\n",
       "value        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S11.isnull().sum() / len(U98P3S11) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates = U98P3S11.duplicated().sum()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های دسته‌بندی‌شده:\n",
      "Index([], dtype='object')\n",
      "ستون‌های عددی:\n",
      "Index(['Address', 'code', 'purchased', 'value'], dtype='object')\n",
      "تعداد داده‌های پرت در ستون code: 372\n",
      "تعداد داده‌های پرت در ستون purchased: 355\n",
      "تعداد داده‌های پرت در ستون value: 1698\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = U98P3S11.select_dtypes(include=['object']).columns\n",
    "print(\"ستون‌های دسته‌بندی‌شده:\")\n",
    "print(categorical_columns)\n",
    "\n",
    "numerical_columns = U98P3S11.select_dtypes(include=['number']).columns\n",
    "print(\"ستون‌های عددی:\")\n",
    "print(numerical_columns)\n",
    "# بررسی داده‌های پرت بر اساس IQR\n",
    "for column in numerical_columns:\n",
    "    Q1 = U98P3S11[column].quantile(0.25)\n",
    "    Q3 = U98P3S11[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((U98P3S11[column] < (Q1 - 1.5 * IQR)) | (U98P3S11[column] > (Q3 + 1.5 * IQR))).sum()\n",
    "    if outliers > 0:\n",
    "        print(f\"تعداد داده‌های پرت در ستون {column}: {outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates = U98P3S12.duplicated().sum()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های دسته‌بندی‌شده:\n",
      "Index([], dtype='object')\n",
      "ستون‌های عددی:\n",
      "Index(['Address', 'code', 'purchased', 'value'], dtype='object')\n",
      "تعداد داده‌های پرت در ستون code: 1095\n",
      "تعداد داده‌های پرت در ستون purchased: 659\n",
      "تعداد داده‌های پرت در ستون value: 6681\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = U98P3S12.select_dtypes(include=['object']).columns\n",
    "print(\"ستون‌های دسته‌بندی‌شده:\")\n",
    "print(categorical_columns)\n",
    "\n",
    "numerical_columns = U98P3S12.select_dtypes(include=['number']).columns\n",
    "print(\"ستون‌های عددی:\")\n",
    "print(numerical_columns)\n",
    "# بررسی داده‌های پرت بر اساس IQR\n",
    "for column in numerical_columns:\n",
    "    Q1 = U98P3S12[column].quantile(0.25)\n",
    "    Q3 = U98P3S12[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((U98P3S12[column] < (Q1 - 1.5 * IQR)) | (U98P3S12[column] > (Q3 + 1.5 * IQR))).sum()\n",
    "    if outliers > 0:\n",
    "        print(f\"تعداد داده‌های پرت در ستون {column}: {outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address    0.000000\n",
       "code       0.000000\n",
       "value      0.386118\n",
       "dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S13.isnull().sum() / len(U98P3S13) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98P3S13 = U98P3S13.dropna(subset=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519\n"
     ]
    }
   ],
   "source": [
    "duplicates = U98P3S13.duplicated().sum()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98P3S13 = U98P3S13.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates = U98P3S13.duplicated().sum()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های دسته‌بندی‌شده:\n",
      "Index(['value'], dtype='object')\n",
      "ستون‌های عددی:\n",
      "Index(['Address', 'code'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = U98P3S13.select_dtypes(include=['object']).columns\n",
    "print(\"ستون‌های دسته‌بندی‌شده:\")\n",
    "print(categorical_columns)\n",
    "\n",
    "numerical_columns = U98P3S13.select_dtypes(include=['number']).columns\n",
    "print(\"ستون‌های عددی:\")\n",
    "print(numerical_columns)\n",
    "# بررسی داده‌های پرت بر اساس IQR\n",
    "for column in numerical_columns:\n",
    "    Q1 = U98P3S13[column].quantile(0.25)\n",
    "    Q3 = U98P3S13[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((U98P3S13[column] < (Q1 - 1.5 * IQR)) | (U98P3S13[column] > (Q3 + 1.5 * IQR))).sum()\n",
    "    if outliers > 0:\n",
    "        print(f\"تعداد داده‌های پرت در ستون {column}: {outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address      0.000000\n",
       "code         0.000000\n",
       "purchased    2.506775\n",
       "value        2.608401\n",
       "dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S14.isnull().sum() / len(U98P3S14) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98P3S14 = U98P3S14.dropna(subset=['purchased','value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address      0.0\n",
       "code         0.0\n",
       "purchased    0.0\n",
       "value        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P3S14.isnull().sum() / len(U98P3S14) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates = U98P3S14.duplicated().sum()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ستون‌های دسته‌بندی‌شده:\n",
      "Index(['purchased'], dtype='object')\n",
      "ستون‌های عددی:\n",
      "Index(['Address', 'code', 'value'], dtype='object')\n",
      "تعداد داده‌های پرت در ستون value: 532\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = U98P3S14.select_dtypes(include=['object']).columns\n",
    "print(\"ستون‌های دسته‌بندی‌شده:\")\n",
    "print(categorical_columns)\n",
    "\n",
    "numerical_columns = U98P3S14.select_dtypes(include=['number']).columns\n",
    "print(\"ستون‌های عددی:\")\n",
    "print(numerical_columns)\n",
    "# بررسی داده‌های پرت بر اساس IQR\n",
    "for column in numerical_columns:\n",
    "    Q1 = U98P3S14[column].quantile(0.25)\n",
    "    Q3 = U98P3S14[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((U98P3S14[column] < (Q1 - 1.5 * IQR)) | (U98P3S14[column] > (Q3 + 1.5 * IQR))).sum()\n",
    "    if outliers > 0:\n",
    "        print(f\"تعداد داده‌های پرت در ستون {column}: {outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address            0.000000\n",
       "member             0.000000\n",
       "employed_w         0.000000\n",
       "ISCO_w             0.000000\n",
       "ISIC_w             0.000000\n",
       "status_w           0.000000\n",
       "hours_w            7.032536\n",
       "days_w             7.032536\n",
       "income_w_m         0.000000\n",
       "income_w_y         0.000000\n",
       "wage_w_m           0.078401\n",
       "wage_w_y           0.031360\n",
       "perk_w_m           0.078401\n",
       "perk_w_y           0.031360\n",
       "netincome_w_m      0.000000\n",
       "netincome_w_y      0.000000\n",
       "Fasl               0.000000\n",
       "year               0.000000\n",
       "DYCOL00          100.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P4S01.isnull().sum() / len(U98P4S01) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98P4S01 = U98P4S01.drop(columns='DYCOL00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "U98P4S01_cleaned = U98P4S01.dropna(subset=['hours_w','days_w','wage_w_m','wage_w_y','perk_w_m','perk_w_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address          0.0\n",
       "member           0.0\n",
       "employed_w       0.0\n",
       "ISCO_w           0.0\n",
       "ISIC_w           0.0\n",
       "status_w         0.0\n",
       "hours_w          0.0\n",
       "days_w           0.0\n",
       "income_w_m       0.0\n",
       "income_w_y       0.0\n",
       "wage_w_m         0.0\n",
       "wage_w_y         0.0\n",
       "perk_w_m         0.0\n",
       "perk_w_y         0.0\n",
       "netincome_w_m    0.0\n",
       "netincome_w_y    0.0\n",
       "Fasl             0.0\n",
       "year             0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P4S01_cleaned.isnull().sum() / len(U98P4S01_cleaned) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address              0.000000\n",
       "member               0.013676\n",
       "employed_s           0.013676\n",
       "ISCO_s               0.027352\n",
       "ISIC_s               0.027352\n",
       "status_s             0.013676\n",
       "agriculture          0.013676\n",
       "hours_s              2.270241\n",
       "days_s               2.256565\n",
       "cost_employment     13.388950\n",
       "cost_raw             2.666849\n",
       "cost_machinery       6.031182\n",
       "cost_others          3.801969\n",
       "cost_tax            12.472648\n",
       "sale                 0.601751\n",
       "income_s_y           0.013676\n",
       "Fasl                 0.000000\n",
       "year                 0.000000\n",
       "DYCOL00            100.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P4S02.isnull().sum() / len(U98P4S02) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98P4S02 = U98P4S02.drop(columns='DYCOL00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98P4S02_cleaned = U98P4S02.dropna(subset=['member','employed_s','ISCO_s','ISIC_s','hours_s','cost_raw','cost_others','sale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address            0.000000\n",
       "member             0.000000\n",
       "employed_s         0.000000\n",
       "ISCO_s             0.000000\n",
       "ISIC_s             0.000000\n",
       "status_s           0.000000\n",
       "agriculture        0.000000\n",
       "hours_s            0.000000\n",
       "days_s             0.000000\n",
       "cost_employment    9.697326\n",
       "cost_raw           0.000000\n",
       "cost_machinery     3.129592\n",
       "cost_others        0.000000\n",
       "cost_tax           8.536585\n",
       "sale               0.000000\n",
       "income_s_y         0.000000\n",
       "Fasl               0.000000\n",
       "year               0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P4S02_cleaned.isnull().sum() / len(U98P4S02_cleaned) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98P4S02_cleaned = U98P4S02.dropna(subset=['cost_employment','cost_machinery','cost_tax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address              0.000000\n",
       "member               0.000000\n",
       "income_pension      53.404400\n",
       "income_rent         68.307467\n",
       "income_interest     37.816795\n",
       "income_aid          52.317500\n",
       "income_resale       72.827507\n",
       "income_transfer     55.954434\n",
       "Fasl                 0.000000\n",
       "year                 0.000000\n",
       "DYCOL00            100.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P4S03.isnull().sum() / len(U98P4S03) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98P4S03 = U98P4S03.drop(columns='DYCOL00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98P4S03_cleaned = U98P4S03.dropna(subset=['member'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address              int64\n",
      "member               int64\n",
      "income_pension      object\n",
      "income_rent         object\n",
      "income_interest    float64\n",
      "income_aid         float64\n",
      "income_resale      float64\n",
      "income_transfer    float64\n",
      "Fasl                 int64\n",
      "year                 int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(U98P4S03_cleaned.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98P4S03_cleaned = U98P4S03_cleaned.apply(pd.to_numeric, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded7 = U98P4S03_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for income_aid : 0.4438356164383562\n"
     ]
    }
   ],
   "source": [
    "df_not_null = df_encoded7[df_encoded7['income_aid'].notnull()]\n",
    "df_null = df_encoded7[df_encoded7['income_aid'].isnull()]\n",
    "\n",
    "\n",
    "X = df_not_null.drop(['income_aid'], axis=1)\n",
    "y = df_not_null['income_aid']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(f'Accuracy for income_aid : {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "\n",
    "X_null = df_null.drop(['income_aid'], axis=1)\n",
    "\n",
    "\n",
    "df_null.loc[:, 'income_aid'] = model.predict(X_null)\n",
    "\n",
    "\n",
    "U98P4S03_filled = pd.concat([df_not_null, df_null])\n",
    "\n",
    "\n",
    "U98P4S03_filled.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "#print(U98P4S031_filled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address             0.0\n",
       "member              0.0\n",
       "subsidy_number      0.0\n",
       "subsidy_month       0.0\n",
       "subsidy             0.0\n",
       "Fasl                0.0\n",
       "year                0.0\n",
       "DYCOL00           100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = U98P4S04.isnull().sum() / len(U98P4S04) * 100\n",
    "missing_percentage.sort_values(ascending=False)  \n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98P4S04 = U98P4S04.drop(columns='DYCOL00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "U98P4S04_cleaned = U98P4S04.dropna(subset=['subsidy_number','subsidy_month','subsidy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_frames = {\n",
    "    'U98Data': U98Data_cleaned,\n",
    "    'R99P1': U98P1_filled,\n",
    "    'R99P2': U98P2,\n",
    "    'Food': U98P3S01_cleaned,\n",
    "    'Tobacco': U98P3S02_cleaned,\n",
    "    'Clothing': U98P3S03,\n",
    "    'Housing': U98P3S04_cleaned,\n",
    "    'Furniture': U98P3S05,\n",
    "    'Health': U98P3S06,\n",
    "    'Transport': U98P3S07,\n",
    "    'Communication': U98P3S08,\n",
    "    'Recreation': U98P3S09,\n",
    "    'Education': U98P3S11,\n",
    "    'Hotel': U98P3S12,\n",
    "    'Miscellaneous': U98P3S13,\n",
    "    'Investment': U98P3S14,\n",
    "    'U98P4S01': U98P4S01_cleaned,\n",
    "    'U98P4S02': U98P4S02_cleaned,\n",
    "    'U98P4S03': U98P4S03_cleaned,\n",
    "    'U98P4S04': U98P4S04_cleaned\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with pd.ExcelWriter('cleaned_data_final_u98.xlsx') as writer:\n",
    "    for sheet_name, df in data_frames.items():\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
